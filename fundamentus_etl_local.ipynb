{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f284881-f982-4740-984f-65e8e1f9da16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 00:54:12,275 - INFO - Iniciando a coleta de dados fundamentalistas do Fundamentus...\n",
      "2025-08-05 00:54:12,281 - WARNING - Executando o script localmente para extração e limpeza de dados.\n",
      "2025-08-05 00:54:12,282 - WARNING - A parte de carga para o SQL Server foi desativada para esta execução local.\n",
      "2025-08-05 00:54:12,283 - INFO - Execução local, usando data/hora atual: 2025-08-05T00:54:12.283135\n",
      "2025-08-05 00:54:12,283 - INFO - Obtendo lista de todos os tickers do Fundamentus...\n",
      "2025-08-05 00:54:14,206 - INFO -   995 tickers encontrados.\n",
      "2025-08-05 00:54:14,207 - INFO - \n",
      "Iniciando coleta de dados para 995 empresas usando 8 threads...\n",
      "2025-08-05 00:54:17,866 - INFO - Progresso de scraping: 50/995 empresas processadas.\n",
      "2025-08-05 00:54:21,439 - INFO - Progresso de scraping: 100/995 empresas processadas.\n",
      "2025-08-05 00:54:24,669 - INFO - Progresso de scraping: 150/995 empresas processadas.\n",
      "2025-08-05 00:54:28,250 - INFO - Progresso de scraping: 200/995 empresas processadas.\n",
      "2025-08-05 00:54:31,693 - INFO - Progresso de scraping: 250/995 empresas processadas.\n",
      "2025-08-05 00:54:34,908 - INFO - Progresso de scraping: 300/995 empresas processadas.\n",
      "2025-08-05 00:54:38,351 - INFO - Progresso de scraping: 350/995 empresas processadas.\n",
      "2025-08-05 00:54:41,613 - INFO - Progresso de scraping: 400/995 empresas processadas.\n",
      "2025-08-05 00:54:45,009 - INFO - Progresso de scraping: 450/995 empresas processadas.\n",
      "2025-08-05 00:54:48,449 - INFO - Progresso de scraping: 500/995 empresas processadas.\n",
      "2025-08-05 00:54:51,839 - INFO - Progresso de scraping: 550/995 empresas processadas.\n",
      "2025-08-05 00:54:55,328 - INFO - Progresso de scraping: 600/995 empresas processadas.\n",
      "2025-08-05 00:54:58,806 - INFO - Progresso de scraping: 650/995 empresas processadas.\n",
      "2025-08-05 00:55:02,653 - INFO - Progresso de scraping: 700/995 empresas processadas.\n",
      "2025-08-05 00:55:06,218 - INFO - Progresso de scraping: 750/995 empresas processadas.\n",
      "2025-08-05 00:55:11,362 - INFO - Progresso de scraping: 800/995 empresas processadas.\n",
      "2025-08-05 00:55:14,902 - INFO - Progresso de scraping: 850/995 empresas processadas.\n",
      "2025-08-05 00:55:18,350 - INFO - Progresso de scraping: 900/995 empresas processadas.\n",
      "2025-08-05 00:55:21,756 - INFO - Progresso de scraping: 950/995 empresas processadas.\n",
      "2025-08-05 00:55:24,914 - INFO - Progresso de scraping: 995/995 empresas processadas.\n",
      "2025-08-05 00:55:24,917 - INFO - \n",
      "Coleta de dados concluída. Criando DataFrame...\n",
      "2025-08-05 00:55:24,974 - INFO - Nomes das colunas alterados. Exemplo original: ['Ticker', 'Papel', 'Cotacao'] -> Limpos: ['ticker', 'papel', 'cotacao']\n",
      "2025-08-05 00:55:25,019 - INFO -   Coluna 'data_ult_cot' convertida para formato 'YYYY-MM-DD' ou None.\n",
      "2025-08-05 00:55:25,038 - INFO -   Coluna 'ult_balanco_processado' convertida para formato 'YYYY-MM-DD' ou None.\n",
      "2025-08-05 00:55:25,047 - INFO -   Coluna 'papel' removida.\n",
      "2025-08-05 00:55:25,056 - INFO -   1 colunas totalmente vazias removidas.\n",
      "\n",
      "2025-08-05 00:55:25,058 - INFO -   Colunas ['1', '2', '3', '4'] removidas.\n",
      "\n",
      "2025-08-05 00:55:25,084 - INFO -   Coluna 'data_execucao' dividida em 'data_execucao' (somente data) e 'hora_execucao'.\n",
      "\n",
      "2025-08-05 00:55:25,089 - INFO - \n",
      "DataFrame final após transformações. Primeiras 5 linhas:\n",
      "2025-08-05 00:55:25,134 - INFO - \n",
      "  ticker data_execucao hora_execucao  cotacao   tipo data_ult_cot                              empresa  min_52_sem                  setor  max_52_sem               subsetor  vol_med_2m  valor_de_mercado ult_balanco_processado valor_da_firma     nro_acoes  dia   pl  lpa  mes  pvp  vpa  30_dias pebit marg_bruta  12_meses   psr marg_ebit pativos marg_liquida pcap_giro  ebit_ativo pativ_circ_liq  roic  div_yield    roe ev_ebitda liquidez_corr ev_ebit div_br_patrim cres_rec_5a giro_ativos         ativo     div_bruta  disponibilidades  div_liquida  ativo_circulante    patrim_liq  receita_liquida_12m  receita_liquida_3m      ebit_12m      ebit_3m  lucro_liquido_12m  lucro_liquido_3m  depositos  cart_de_credito  result_int_financ_12m  result_int_financ_3m  rec_servicos_12m  rec_servicos_3m  2010  2011  2012  2013  2014  2015  2016  2017  2018  2019  2020  2021  2022  2023  2024  2025\n",
      "0  MNSA4    2025-08-05      00:54:12     0.47     PN   2006-03-23                            MANASA PN         0.0                                0.0                                0.0               0.0             2005-12-31           <NA>  0.000000e+00  0.0  0.0  0.0  0.0  0.0  0.0      0.0  <NA>       66.8       0.0  <NA>    -208.1    <NA>       -362.7      <NA>       -10.6           <NA> -13.5        0.0  145.7      <NA>          3.63    <NA>         -6.52       -41.1        0.05  7.151700e+07  5.933500e+07        12346000.0   46989000.0      1.714200e+07 -9.105000e+06         3.658000e+06        1.185000e+06 -7.614000e+06   -2978000.0      -1.326600e+07        -7097000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0   0.0   0.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "1  IVTT3    2025-08-05      00:54:12     0.00  ON NM         None                            BHG ON NM         0.0  Exploração de Imóveis         0.0  Exploração de Imóveis         0.0               0.0             2015-03-31           <NA>  6.214140e+07  0.0  0.0  0.0  0.0  0.0  0.0      0.0  <NA>       <NA>       0.0  <NA>      <NA>    <NA>          0.0      <NA>         0.0           <NA>  <NA>        0.0   -0.4      <NA>          <NA>    <NA>          <NA>        20.7        <NA>  1.387870e+09  2.121540e+08        99506000.0  112648000.0      1.661140e+08  1.083050e+09         3.285190e+08        6.847900e+07  5.007200e+07   -2673000.0      -4.361000e+06       -10915000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "2  POPR4    2025-08-05      00:54:12    10.17     PN   2005-11-08                POLIPROPILENO S.A. PN         0.0                                0.0                                0.0               0.0             2005-09-30           <NA>  0.000000e+00  0.0  0.0  0.0  0.0  0.0  0.0      0.0  <NA>       16.4       0.0  <NA>       8.7    <NA>          5.6      <NA>        13.4           <NA>  15.3        0.0   19.9      <NA>          1.08    <NA>          0.82        30.9        1.55  1.242060e+09  4.488720e+08        17784000.0  431088000.0      4.645190e+08  5.458030e+08         1.925960e+09        5.216010e+08  1.667450e+08   24027000.0       1.087840e+08        16842000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0   0.0   0.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "3  CSTB4    2025-08-05      00:54:12   147.69     PN   2005-11-10  COMPANHIA SIDERÚRGICA DE TUBARÃO PN         0.0                                0.0                                0.0               0.0             2005-09-30           <NA>  0.000000e+00  0.0  0.0  0.0  0.0  0.0  0.0      0.0  <NA>       45.4       0.0  <NA>      40.8    <NA>         29.0      <NA>        21.1           <NA>  22.4        0.0   20.1      <NA>           2.6    <NA>          0.14        31.9        0.52  1.129640e+10  1.162560e+09       404435000.0  758130000.0      1.937480e+09  8.420670e+09         5.842730e+09        1.047730e+09  2.386670e+09  290700000.0       1.693390e+09       173262000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0   0.0   0.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "4  PMET3    2025-08-05      00:54:12     0.00     ON         None                      PRO METALURG ON         0.0                                0.0                                0.0               0.0             2013-12-31           <NA>  7.241000e+10  0.0  0.0  0.0  0.0  0.0  0.0      0.0  <NA>       <NA>       0.0  <NA>      <NA>    <NA>          0.0      <NA>         0.0           <NA>  <NA>        0.0    4.1      <NA>          <NA>    <NA>          <NA>        37.7        <NA>  1.556000e+06  2.166720e+08          211000.0  216461000.0      1.323000e+06 -2.908630e+08         1.041800e+07        7.699000e+06  5.230000e+05     302000.0      -1.192800e+07        -8936000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "2025-08-05 00:55:25,135 - INFO - \n",
      "Informações do DataFrame final:\n",
      "2025-08-05 00:55:25,224 - INFO - \n",
      "Dados salvos em 'data/carga_fundamentus_20250805_005412.csv'\n",
      "2025-08-05 00:55:25,225 - INFO - \n",
      "Processo ETL finalizado em 72.94 segundos. ✅\n",
      "2025-08-05 00:55:25,231 - INFO - \n",
      "--- Dados Extraídos e Limpos (Primeiras 10 linhas) ---\n",
      "2025-08-05 00:55:25,281 - INFO - \n",
      "DataFrame final contém 995 linhas e 76 colunas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 995 entries, 0 to 994\n",
      "Data columns (total 76 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   ticker                  995 non-null    object \n",
      " 1   data_execucao           995 non-null    object \n",
      " 2   hora_execucao           995 non-null    object \n",
      " 3   cotacao                 995 non-null    float64\n",
      " 4   tipo                    995 non-null    object \n",
      " 5   data_ult_cot            981 non-null    object \n",
      " 6   empresa                 995 non-null    object \n",
      " 7   min_52_sem              995 non-null    float64\n",
      " 8   setor                   995 non-null    object \n",
      " 9   max_52_sem              995 non-null    float64\n",
      " 10  subsetor                995 non-null    object \n",
      " 11  vol_med_2m              995 non-null    float64\n",
      " 12  valor_de_mercado        995 non-null    float64\n",
      " 13  ult_balanco_processado  995 non-null    object \n",
      " 14  valor_da_firma          885 non-null    object \n",
      " 15  nro_acoes               995 non-null    float64\n",
      " 16  dia                     995 non-null    float64\n",
      " 17  pl                      995 non-null    float64\n",
      " 18  lpa                     995 non-null    float64\n",
      " 19  mes                     995 non-null    float64\n",
      " 20  pvp                     995 non-null    float64\n",
      " 21  vpa                     995 non-null    float64\n",
      " 22  30_dias                 995 non-null    float64\n",
      " 23  pebit                   848 non-null    object \n",
      " 24  marg_bruta              843 non-null    object \n",
      " 25  12_meses                995 non-null    float64\n",
      " 26  psr                     806 non-null    object \n",
      " 27  marg_ebit               843 non-null    object \n",
      " 28  pativos                 854 non-null    object \n",
      " 29  marg_liquida            967 non-null    object \n",
      " 30  pcap_giro               827 non-null    object \n",
      " 31  ebit_ativo              995 non-null    float64\n",
      " 32  pativ_circ_liq          827 non-null    object \n",
      " 33  roic                    860 non-null    object \n",
      " 34  div_yield               995 non-null    float64\n",
      " 35  roe                     967 non-null    object \n",
      " 36  ev_ebitda               875 non-null    object \n",
      " 37  liquidez_corr           862 non-null    object \n",
      " 38  ev_ebit                 877 non-null    object \n",
      " 39  div_br_patrim           794 non-null    object \n",
      " 40  cres_rec_5a             934 non-null    object \n",
      " 41  giro_ativos             843 non-null    object \n",
      " 42  ativo                   995 non-null    float64\n",
      " 43  div_bruta               914 non-null    float64\n",
      " 44  disponibilidades        914 non-null    float64\n",
      " 45  div_liquida             914 non-null    float64\n",
      " 46  ativo_circulante        914 non-null    float64\n",
      " 47  patrim_liq              995 non-null    float64\n",
      " 48  receita_liquida_12m     914 non-null    float64\n",
      " 49  receita_liquida_3m      914 non-null    float64\n",
      " 50  ebit_12m                914 non-null    float64\n",
      " 51  ebit_3m                 914 non-null    float64\n",
      " 52  lucro_liquido_12m       995 non-null    float64\n",
      " 53  lucro_liquido_3m        995 non-null    float64\n",
      " 54  depositos               81 non-null     float64\n",
      " 55  cart_de_credito         81 non-null     float64\n",
      " 56  result_int_financ_12m   81 non-null     float64\n",
      " 57  result_int_financ_3m    81 non-null     float64\n",
      " 58  rec_servicos_12m        81 non-null     float64\n",
      " 59  rec_servicos_3m         81 non-null     float64\n",
      " 60  2010                    2 non-null      float64\n",
      " 61  2011                    2 non-null      float64\n",
      " 62  2012                    2 non-null      float64\n",
      " 63  2013                    329 non-null    float64\n",
      " 64  2014                    394 non-null    float64\n",
      " 65  2015                    408 non-null    float64\n",
      " 66  2016                    423 non-null    float64\n",
      " 67  2017                    454 non-null    float64\n",
      " 68  2018                    471 non-null    float64\n",
      " 69  2019                    173 non-null    float64\n",
      " 70  2020                    587 non-null    float64\n",
      " 71  2021                    573 non-null    float64\n",
      " 72  2022                    556 non-null    float64\n",
      " 73  2023                    525 non-null    float64\n",
      " 74  2024                    508 non-null    float64\n",
      " 75  2025                    479 non-null    float64\n",
      "dtypes: float64(50), object(26)\n",
      "memory usage: 590.9+ KB\n",
      "  ticker data_execucao hora_execucao  cotacao   tipo data_ult_cot                              empresa  min_52_sem                    setor  max_52_sem                 subsetor  vol_med_2m  valor_de_mercado ult_balanco_processado valor_da_firma     nro_acoes  dia       pl   lpa  mes      pvp     vpa  30_dias    pebit marg_bruta  12_meses   psr marg_ebit pativos marg_liquida pcap_giro  ebit_ativo pativ_circ_liq  roic  div_yield    roe ev_ebitda liquidez_corr  ev_ebit div_br_patrim cres_rec_5a giro_ativos         ativo     div_bruta  disponibilidades  div_liquida  ativo_circulante    patrim_liq  receita_liquida_12m  receita_liquida_3m      ebit_12m      ebit_3m  lucro_liquido_12m  lucro_liquido_3m  depositos  cart_de_credito  result_int_financ_12m  result_int_financ_3m  rec_servicos_12m  rec_servicos_3m  2010  2011  2012  2013  2014  2015  2016  2017  2018  2019  2020  2021  2022  2023  2024    2025\n",
      "0  MNSA4    2025-08-05      00:54:12     0.47     PN   2006-03-23                            MANASA PN        0.00                                 0.00                                  0.0               0.0             2005-12-31           <NA>  0.000000e+00  0.0     0.00  0.00  0.0     0.00    0.00     0.00     <NA>       66.8      0.00  <NA>    -208.1    <NA>       -362.7      <NA>       -10.6           <NA> -13.5        0.0  145.7      <NA>          3.63     <NA>         -6.52       -41.1        0.05  7.151700e+07  5.933500e+07        12346000.0   46989000.0      1.714200e+07 -9.105000e+06         3.658000e+06        1.185000e+06 -7.614000e+06   -2978000.0      -1.326600e+07        -7097000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0   0.0   0.0   NaN   NaN   NaN   NaN   NaN   NaN     NaN\n",
      "1  IVTT3    2025-08-05      00:54:12     0.00  ON NM         None                            BHG ON NM        0.00    Exploração de Imóveis        0.00    Exploração de Imóveis         0.0               0.0             2015-03-31           <NA>  6.214140e+07  0.0     0.00  0.00  0.0     0.00    0.00     0.00     <NA>       <NA>      0.00  <NA>      <NA>    <NA>          0.0      <NA>         0.0           <NA>  <NA>        0.0   -0.4      <NA>          <NA>     <NA>          <NA>        20.7        <NA>  1.387870e+09  2.121540e+08        99506000.0  112648000.0      1.661140e+08  1.083050e+09         3.285190e+08        6.847900e+07  5.007200e+07   -2673000.0      -4.361000e+06       -10915000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN\n",
      "2  POPR4    2025-08-05      00:54:12    10.17     PN   2005-11-08                POLIPROPILENO S.A. PN        0.00                                 0.00                                  0.0               0.0             2005-09-30           <NA>  0.000000e+00  0.0     0.00  0.00  0.0     0.00    0.00     0.00     <NA>       16.4      0.00  <NA>       8.7    <NA>          5.6      <NA>        13.4           <NA>  15.3        0.0   19.9      <NA>          1.08     <NA>          0.82        30.9        1.55  1.242060e+09  4.488720e+08        17784000.0  431088000.0      4.645190e+08  5.458030e+08         1.925960e+09        5.216010e+08  1.667450e+08   24027000.0       1.087840e+08        16842000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0   0.0   0.0   NaN   NaN   NaN   NaN   NaN   NaN     NaN\n",
      "3  CSTB4    2025-08-05      00:54:12   147.69     PN   2005-11-10  COMPANHIA SIDERÚRGICA DE TUBARÃO PN        0.00                                 0.00                                  0.0               0.0             2005-09-30           <NA>  0.000000e+00  0.0     0.00  0.00  0.0     0.00    0.00     0.00     <NA>       45.4      0.00  <NA>      40.8    <NA>         29.0      <NA>        21.1           <NA>  22.4        0.0   20.1      <NA>           2.6     <NA>          0.14        31.9        0.52  1.129640e+10  1.162560e+09       404435000.0  758130000.0      1.937480e+09  8.420670e+09         5.842730e+09        1.047730e+09  2.386670e+09  290700000.0       1.693390e+09       173262000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0   0.0   0.0   NaN   NaN   NaN   NaN   NaN   NaN     NaN\n",
      "4  PMET3    2025-08-05      00:54:12     0.00     ON         None                      PRO METALURG ON        0.00                                 0.00                                  0.0               0.0             2013-12-31           <NA>  7.241000e+10  0.0     0.00  0.00  0.0     0.00    0.00     0.00     <NA>       <NA>      0.00  <NA>      <NA>    <NA>          0.0      <NA>         0.0           <NA>  <NA>        0.0    4.1      <NA>          <NA>     <NA>          <NA>        37.7        <NA>  1.556000e+06  2.166720e+08          211000.0  216461000.0      1.323000e+06 -2.908630e+08         1.041800e+07        7.699000e+06  5.230000e+05     302000.0      -1.192800e+07        -8936000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN\n",
      "5  PORP4    2025-08-05      00:54:12     2.40     PN   2005-11-25  POLIPROPILENO PARTICIPAÇÕES S.A. PN        0.00                                 0.00                                  0.0               0.0             2005-09-30           <NA>  0.000000e+00  0.0     0.00  0.00  0.0     0.00    0.00     0.00     <NA>       <NA>      0.00  <NA>      <NA>    <NA>          0.0      <NA>        -0.5           <NA>  <NA>        0.0   -2.1      <NA>          <NA>     <NA>          <NA>        13.7        <NA>  2.534100e+07  0.000000e+00          189000.0    -189000.0      5.140000e+05  2.239900e+07         0.000000e+00        0.000000e+00 -1.220000e+05     -12000.0      -4.650000e+05          -46000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0   0.0   0.0   NaN   NaN   NaN   NaN   NaN   NaN     NaN\n",
      "6  CLAN3    2025-08-05      00:54:12     0.00     ON         None                           CLARION ON        0.00                                 0.00                                  0.0               0.0             2012-12-31           <NA>  1.587030e+08  0.0     0.00  0.00  0.0     0.00    0.00     0.00     <NA>       <NA>      0.00  <NA>      <NA>    <NA>          0.0      <NA>         0.0           <NA>  <NA>        0.0   -1.0      <NA>          <NA>     <NA>          <NA>       -64.0        <NA>  1.171790e+09  8.579800e+07            8000.0   85790000.0      8.464100e+07  1.012240e+09         3.142500e+07        4.309000e+06 -5.767000e+06   38487000.0      -1.060000e+07        41218000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN\n",
      "7  CFLU4    2025-08-05      00:54:12  1000.00     PN   2003-02-13                         COCA COLA PN        0.00                                 0.00                                  0.0               0.0             2005-09-30           <NA>  0.000000e+00  0.0     0.00  0.00  0.0     0.00    0.00     0.00     <NA>       39.3      0.00  <NA>       8.9    <NA>         10.7      <NA>        14.3           <NA>  17.7        0.0   32.2      <NA>           1.1     <NA>          0.06         8.1        1.62  1.120070e+08  3.453000e+06         5856000.0   -2403000.0      3.343800e+07  6.035100e+07         1.810420e+08        4.480600e+07  1.607100e+07    4041000.0       1.940300e+07         3479000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0   0.0   0.0   NaN   NaN   NaN   NaN   NaN   NaN     NaN\n",
      "8  MSPA3    2025-08-05      00:54:12    46.00     ON   2025-07-30                     MELHORAMENTOS ON       41.89          Madeira e Papel       46.88         Papel e Celulose       329.0       294630000.0             2025-03-31    442518000.0  6.405000e+06  0.0 -7186.10 -0.01  0.0     0.35  130.46     0.00   -17.98       36.2      7.99  1.77      -9.9     0.2          0.0     -7.47        -1.1          -0.57  -1.2        0.3    0.0   -194.86          0.76   -27.01          0.23         9.3        0.11  1.470000e+09  1.919730e+08        44085000.0  147888000.0      1.218720e+08  8.355620e+08         1.662810e+08        4.338800e+07 -1.638400e+07   -2312000.0      -4.100000e+04       -10318000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  6.67  1.04  3.11 -7.52  2.44   -1.87\n",
      "9  ADMF3    2025-08-05      00:54:12   110.73  ON NM   2025-07-31                       CIABRASF ON NM       33.02  Holdings Diversificadas      113.00  Holdings Diversificadas     16325.0       645999000.0             2024-12-31    645999000.0  5.834000e+06  0.0 -3588.88 -0.03  0.0 -6211.53   -0.02   189.57 -3629.21       <NA>    235.34  <NA>      <NA>   22.21          0.0      <NA>        -0.6           <NA>  <NA>        0.0  173.1  -3629.21          <NA> -3629.21          <NA>        <NA>        <NA>  2.908200e+07  0.000000e+00               0.0          0.0      0.000000e+00 -1.040000e+05         0.000000e+00        0.000000e+00 -1.780000e+05     -89000.0      -1.800000e+05          -90000.0        NaN              NaN                    NaN                   NaN               NaN              NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  0.00  0.00  0.00  0.00  0.00  235.34\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import unicodedata\n",
    "import concurrent.futures\n",
    "import random\n",
    "import logging\n",
    "from datetime import datetime # Usaremos datetime para o timestamp local\n",
    "\n",
    "# --- Configuração de Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "logging.info(\"Iniciando a coleta de dados fundamentalistas do Fundamentus...\")\n",
    "\n",
    "BASE_URL = \"http://www.fundamentus.com.br/\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# --- Função auxiliar para normalizar strings (remove acentos, caracteres diacríticos, espaços extras, etc.) ---\n",
    "def normalize_string_for_comparison(s: str) -> str:\n",
    "    # REMOVE O CARACTERE '?' INICIAL SE EXISTIR\n",
    "    if s.startswith('?'):\n",
    "        s = s[1:]\n",
    "    # Remove acentos e caracteres diacríticos\n",
    "    s = unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('utf-8').strip()\n",
    "    # Troca espaços não quebráveis por espaços normais\n",
    "    s = s.replace('\\xa0', ' ').strip()\n",
    "    # Remove múltiplos espaços e garante um único espaço entre as palavras\n",
    "    s = ' '.join(s.split())\n",
    "    return s\n",
    "\n",
    "# --- LISTAS RAW: Strings EXATAS como aparecem no site (antes de remover ':') ---\n",
    "STRING_FIELDS_RAW = [\n",
    "    \"Tipo:\",\n",
    "    \"Empresa:\",\n",
    "    \"Setor:\",\n",
    "    \"Subsetor:\",\n",
    "    \"Data últ cot:\", \n",
    "    \"Últ balanço processado:\", \n",
    "]\n",
    "\n",
    "SPECIAL_METRICS_RAW = [\n",
    "    \"Receita Líquida:\",\n",
    "    \"EBIT:\",\n",
    "    \"Lucro Líquido:\",\n",
    "    \"Result Int Financ:\",\n",
    "    \"Rec Serviços:\",\n",
    "]\n",
    "\n",
    "# --- NORMALIZAÇÃO DAS LISTAS UMA ÚNICA VEZ NO INÍCIO DO SCRIPT ---\n",
    "STRING_FIELDS = [normalize_string_for_comparison(s.replace(\":\", \"\")) for s in STRING_FIELDS_RAW]\n",
    "SPECIAL_METRICS = [normalize_string_for_comparison(s.replace(\":\", \"\")) for s in SPECIAL_METRICS_RAW]\n",
    "\n",
    "# --- Lista de colunas que devem ser convertidas para DATE no SQL Server ---\n",
    "# Estes são os nomes das colunas APÓS a limpeza por clean_column_name\n",
    "DATE_COLUMNS_TO_CONVERT = [\n",
    "    \"data_ult_cot\",\n",
    "    \"ult_balanco_processado\"\n",
    "]\n",
    "\n",
    "def clean_and_convert_value(value_str):\n",
    "    \"\"\"\n",
    "    Limpa e converte uma string para um valor numérico (float),\n",
    "    tratando moedas, porcentagens e separadores decimais.\n",
    "    \"\"\"\n",
    "    if isinstance(value_str, (int, float)):\n",
    "        return value_str\n",
    "    \n",
    "    value_str = str(value_str).strip() # Garante que é string\n",
    "    value_str = value_str.replace(\"R\\$\", \"\").replace(\"%\", \"\").replace(\".\", \"\").replace(\",\", \".\").strip()\n",
    "    \n",
    "    try:\n",
    "        float_val = float(value_str)\n",
    "        return float_val\n",
    "    except ValueError:\n",
    "        return pd.NA\n",
    "\n",
    "# 1) Alterar os nomes das colunas para retirar os caracteres especiais\n",
    "def clean_column_name(col_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Limpa o nome de uma coluna, removendo acentos, caracteres especiais,\n",
    "    substituindo espaços por underscores e convertendo para minúsculas.\n",
    "    \"\"\"\n",
    "    # Normaliza caracteres Unicode (ex: 'ç' -> 'c', 'é' -> 'e')\n",
    "    cleaned_name = unicodedata.normalize('NFKD', col_name).encode('ascii', 'ignore').decode('utf-8')\n",
    "    # Substitui espaços e hifens por underscores\n",
    "    cleaned_name = cleaned_name.replace(' ', '_').replace('-', '_')\n",
    "    # Remove qualquer caractere que não seja letra, número ou underscore\n",
    "    cleaned_name = re.sub(r'[^a-zA-Z0-9_]', '', cleaned_name)\n",
    "    # Remove underscores duplicados ou no início/fim\n",
    "    cleaned_name = re.sub(r'_+', '_', cleaned_name).strip('_')\n",
    "    # Converte para minúsculas\n",
    "    cleaned_name = cleaned_name.lower()\n",
    "    return cleaned_name\n",
    "\n",
    "def scrape_company_data(ticker: str) -> dict:\n",
    "    \"\"\"\n",
    "    Coleta dados de uma única empresa no Fundamentus.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}detalhes.php?papel={ticker}\"\n",
    "    company_data = {\"Ticker\": ticker}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        response.raise_for_status() # Lança exceção para status HTTP de erro\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.warning(f\"  Erro ao acessar a página de {ticker}: {e}\")\n",
    "        return company_data\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    label_tds = soup.find_all(\"td\", class_=\"label\")\n",
    "    \n",
    "    for label_tag in label_tds:\n",
    "        raw_label_from_html = label_tag.text.strip()\n",
    "        \n",
    "        # Remove o ':' e então normaliza para comparação e uso como chave\n",
    "        processed_label_no_colon = raw_label_from_html.replace(\":\", \"\")\n",
    "        normalized_label = normalize_string_for_comparison(processed_label_no_colon)\n",
    "\n",
    "        # Este bloco é para SPECIAL_METRICS (Receita Líquida, EBIT, etc.)\n",
    "        if normalized_label in SPECIAL_METRICS:\n",
    "            parent_row = label_tag.find_parent(\"tr\")\n",
    "            if parent_row:\n",
    "                data_cells = parent_row.find_all(\"td\", class_=\"data\")\n",
    "                if len(data_cells) >= 2:\n",
    "                    value_12m = data_cells[0].text.strip()\n",
    "                    value_3m = data_cells[1].text.strip()\n",
    "\n",
    "                    # Adiciona ao dicionário com os nomes normalizados e sufixos\n",
    "                    company_data[f\"{normalized_label} 12m\"] = value_12m\n",
    "                    company_data[f\"{normalized_label} 3m\"] = value_3m\n",
    "        else:\n",
    "            data_tag = label_tag.find_next_sibling(\"td\", class_=\"data\")\n",
    "            if data_tag:\n",
    "                value = data_tag.text.strip()\n",
    "                company_data[normalized_label] = value # Usa o nome normalizado como chave\n",
    "    \n",
    "    # Após popular company_data, processa os valores\n",
    "    for key, value in company_data.items():\n",
    "        # Verifica se a chave (label normalizado) está em STRING_FIELDS\n",
    "        # E também não converte colunas que serão tratadas como datas\n",
    "        if key != \"Ticker\" and key not in STRING_FIELDS and clean_column_name(key) not in DATE_COLUMNS_TO_CONVERT:\n",
    "            company_data[key] = clean_and_convert_value(value)\n",
    "\n",
    "    time.sleep(random.uniform(0.1, 0.5)) # Pequeno delay para evitar sobrecarga no servidor\n",
    "    return company_data\n",
    "\n",
    "def get_all_tickers() -> list:\n",
    "    \"\"\"\n",
    "    Obtém a lista de todos os tickers de empresas disponíveis no Fundamentus.\n",
    "    \"\"\"\n",
    "    logging.info(\"Obtendo lista de todos os tickers do Fundamentus...\")\n",
    "    tickers = []\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}resultado.php\", headers=HEADERS, timeout=20)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        table = soup.find(\"table\", class_=\"resultado\")\n",
    "        \n",
    "        if table:\n",
    "            rows = table.find_all(\"tr\")\n",
    "            for row in rows[1:]: # Ignora a linha de cabeçalho\n",
    "                cols = row.find_all(\"td\")\n",
    "                if cols and cols[0].find('a'): # Verifica se a primeira coluna contém um link (um ticker)\n",
    "                    ticker = cols[0].text.strip()\n",
    "                    tickers.append(ticker)\n",
    "        else:\n",
    "            logging.warning(\"    AVISO: Tabela de resultados não encontrada na página de tickers.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"  Erro ao acessar a página de resultados para obter tickers: {e}\")\n",
    "    \n",
    "    logging.info(f\"  {len(tickers)} tickers encontrados.\")\n",
    "    return tickers\n",
    "\n",
    "# --- Função principal para ETL (versão local) ---\n",
    "def etl_fundamentus_data():\n",
    "    \"\"\"\n",
    "    Função principal que orquestra o processo de ETL (Extração, Transformação)\n",
    "    dos dados fundamentalistas do Fundamentus para execução local.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Obter o timestamp de execução local ---\n",
    "    timestamp_local = datetime.now()\n",
    "    logging.info(f\"Execução local, usando data/hora atual: {timestamp_local.isoformat()}\")\n",
    "\n",
    "    # --- Extração ---\n",
    "    all_tickers = get_all_tickers() \n",
    "    if not all_tickers:\n",
    "        logging.error(\"Nenhum ticker encontrado. Encerrando o processo ETL.\")\n",
    "        return pd.DataFrame() \n",
    "\n",
    "    all_companies_data = []\n",
    "    MAX_WORKERS = 8 \n",
    "    \n",
    "    logging.info(f\"\\nIniciando coleta de dados para {len(all_tickers)} empresas usando {MAX_WORKERS} threads...\")\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {executor.submit(scrape_company_data, ticker): ticker for ticker in all_tickers}\n",
    "        \n",
    "        processed_count = 0\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            ticker = futures[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                if data:\n",
    "                    # Adiciona o timestamp de execução a cada registro\n",
    "                    data['Data_Execucao'] = timestamp_local\n",
    "                    all_companies_data.append(data)\n",
    "            except Exception as exc:\n",
    "                logging.error(f\"  Ticker {ticker} gerou uma exceção durante scraping: {exc}\")\n",
    "            processed_count += 1\n",
    "            if processed_count % 50 == 0 or processed_count == len(all_tickers):\n",
    "                logging.info(f\"Progresso de scraping: {processed_count}/{len(all_tickers)} empresas processadas.\")\n",
    "\n",
    "    logging.info(\"\\nColeta de dados concluída. Criando DataFrame...\")\n",
    "    df = pd.DataFrame(all_companies_data)\n",
    "    \n",
    "    # --- Transformação ---\n",
    "\n",
    "    # 1) Alterar os nomes das colunas\n",
    "    original_columns = df.columns.tolist()\n",
    "    df.columns = [clean_column_name(col) for col in df.columns]\n",
    "    logging.info(f\"Nomes das colunas alterados. Exemplo original: {original_columns[:3]} -> Limpos: {df.columns.tolist()[:3]}\")\n",
    "\n",
    "    # --- Conversão de colunas de data para formato 'YYYY-MM-DD' ---\n",
    "    for col_name in DATE_COLUMNS_TO_CONVERT:\n",
    "        if col_name in df.columns:\n",
    "            # Explicitamente substitui '-' (e outros valores que podem indicar nulo) por pd.NA\n",
    "            df[col_name] = df[col_name].replace(['-', ''], pd.NA)\n",
    "            \n",
    "            # Converte para objetos datetime. Datas inválidas se tornam NaT (Not a Time).\n",
    "            df[col_name] = pd.to_datetime(df[col_name], format='%d/%m/%Y', errors='coerce')\n",
    "            \n",
    "            # Formata para 'YYYY-MM-DD'. Valores NaT são convertidos para None.\n",
    "            df[col_name] = df[col_name].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notna(x) else None)\n",
    "            logging.info(f\"  Coluna '{col_name}' convertida para formato 'YYYY-MM-DD' ou None.\")\n",
    "        else:\n",
    "            logging.warning(f\"  Coluna de data '{col_name}' não encontrada no DataFrame para conversão.\")\n",
    "\n",
    "    # Remover colunas específicas, agora usando os nomes limpos\n",
    "    if 'papel' in df.columns:\n",
    "        df.drop(columns=['papel'], inplace=True)\n",
    "        logging.info(\"  Coluna 'papel' removida.\")\n",
    "    \n",
    "    original_cols_count = df.shape[1]\n",
    "    df.dropna(axis=1, how='all', inplace=True) # Remove colunas totalmente vazias\n",
    "    if df.shape[1] < original_cols_count:\n",
    "        logging.info(f\"  {original_cols_count - df.shape[1]} colunas totalmente vazias removidas.\\n\")\n",
    "\n",
    "    # Colunas numéricas que não são afetadas pela limpeza de nome, mas podem ser removidas se necessário\n",
    "    cols_to_drop_by_name = ['1', '2', '3', '4'] \n",
    "    existing_cols_to_drop = [col for col in cols_to_drop_by_name if col in df.columns]\n",
    "    if existing_cols_to_drop:\n",
    "        df.drop(columns=existing_cols_to_drop, inplace=True)\n",
    "        logging.info(f\"  Colunas {existing_cols_to_drop} removidas.\\n\")\n",
    "\n",
    "    # 2) Dividir 'data_execucao' em 'data_execucao' (apenas data) e 'hora_execucao'\n",
    "    if 'data_execucao' in df.columns:\n",
    "        df['data_execucao'] = pd.to_datetime(df['data_execucao']) # Garante que é datetime para manipulação\n",
    "        df['hora_execucao'] = df['data_execucao'].dt.strftime('%H:%M:%S') # Extrai apenas a hora\n",
    "        df['data_execucao'] = df['data_execucao'].dt.strftime('%Y-%m-%d') # Formata 'data_execucao' como 'YYYY-MM-DD'\n",
    "        logging.info(\"  Coluna 'data_execucao' dividida em 'data_execucao' (somente data) e 'hora_execucao'.\\n\")\n",
    "    else:\n",
    "        logging.warning(\"  Coluna 'data_execucao' não encontrada para divisão de data/hora.\\n\")\n",
    "\n",
    "    # Reordenar colunas com os novos nomes limpos e a nova coluna 'hora_execucao'\n",
    "    current_columns = df.columns.tolist()\n",
    "    year_columns = []\n",
    "    other_columns = []\n",
    "    \n",
    "    for col in current_columns:\n",
    "        # Regex para anos: Apenas 4 dígitos numéricos (como '2020')\n",
    "        if re.fullmatch(r'\\d{4}', col) and 1900 <= int(col) <= 2100: \n",
    "            year_columns.append(col)\n",
    "        else:\n",
    "            other_columns.append(col)\n",
    "            \n",
    "    year_columns.sort(key=int) \n",
    "    \n",
    "    final_column_order = []\n",
    "    # Posicionar 'ticker', 'data_execucao' e 'hora_execucao' no início\n",
    "    if 'ticker' in other_columns:\n",
    "        final_column_order.append('ticker')\n",
    "        other_columns.remove('ticker')\n",
    "    \n",
    "    if 'data_execucao' in other_columns:\n",
    "        final_column_order.append('data_execucao')\n",
    "        other_columns.remove('data_execucao')\n",
    "\n",
    "    if 'hora_execucao' in other_columns:\n",
    "        final_column_order.append('hora_execucao')\n",
    "        other_columns.remove('hora_execucao')\n",
    "    \n",
    "    final_column_order.extend(other_columns) \n",
    "    final_column_order.extend(year_columns)  \n",
    "    \n",
    "    df = df[final_column_order] \n",
    "    \n",
    "    logging.info(\"\\nDataFrame final após transformações. Primeiras 5 linhas:\")\n",
    "    logging.info(f\"\\n{df.head().to_string()}\") \n",
    "    \n",
    "    logging.info(\"\\nInformações do DataFrame final:\")\n",
    "    df.info()\n",
    "\n",
    "    # --- Salvar CSV com nome dinâmico ---\n",
    "    try:\n",
    "        # Garante que a pasta 'data' exista\n",
    "        import os\n",
    "        os.makedirs('data', exist_ok=True)\n",
    "\n",
    "        csv_filename = f\"carga_fundamentus_{timestamp_local.strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        csv_filepath = f\"data/{csv_filename}\" \n",
    "        df.to_csv(csv_filepath, index=False, encoding=\"utf-8-sig\")\n",
    "        logging.info(f\"\\nDados salvos em '{csv_filepath}'\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao salvar o arquivo CSV: {e}\")\n",
    "\n",
    "    end_time = time.time() \n",
    "    total_time = end_time - start_time \n",
    "    logging.info(f\"\\nProcesso ETL finalizado em {total_time:.2f} segundos. ✅\") \n",
    "\n",
    "    return df \n",
    "\n",
    "# --- Bloco de execução principal para testes locais ---\n",
    "if __name__ == \"__main__\":\n",
    "    logging.warning(\"Executando o script localmente para extração e limpeza de dados.\")\n",
    "    logging.warning(\"A parte de carga para o SQL Server foi desativada para esta execução local.\")\n",
    "\n",
    "    # Chama a função principal de ETL\n",
    "    final_df = etl_fundamentus_data()\n",
    "\n",
    "    if final_df is not None and not final_df.empty:\n",
    "        logging.info(\"\\n--- Dados Extraídos e Limpos (Primeiras 10 linhas) ---\")\n",
    "        print(final_df.head(10).to_string())\n",
    "        logging.info(f\"\\nDataFrame final contém {len(final_df)} linhas e {len(final_df.columns)} colunas.\")\n",
    "    else:\n",
    "        logging.warning(\"Nenhum dado foi processado ou o DataFrame está vazio.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
